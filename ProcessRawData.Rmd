---
title: "Process Raw Data"
author: "Kate Belisle"
date: "2/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
require(tidyverse)
require(dplyr)
require(glue)
```

#Pull data outlined in 
http://www.climate-lab-book.ac.uk/2018/warming-stripes/

#Annual global temperatures from 1850-2017
https://www.metoffice.gov.uk/hadobs/hadcrut4/data/current/download.html


#Format https://www.metoffice.gov.uk/hadobs/hadcrut4/data/current/series_format.html

##These 'best estimate' series are computed as the medians of regional time series computed for each of the 100 ensemble member realisations. Time series are presented as temperature anomalies (deg C) relative to 1961-1990.

##Quoted uncertainties are computed by integrating across the distribution described by the 100 ensemble members, together with additional measurement and sampling error and coverage uncertainty information.

The data files contain 12 columns:  

Column 1 is the date.  
Column 2 is the median of the 100 ensemble member time series.  
Columns 3 and 4 are the lower and upper bounds of the 95% confidence  interval of bias uncertainty computed from the 100 member ensemble.  
Columns 5 and 6 are the lower and upper bounds of the 95% confidence interval of measurement and sampling uncertainties around the ensemble median. These are the combination of fully uncorrelated measurement and sampling uncertainties and partially correlated uncertainties described by the HadCRUT4 error covariance matrices.  
Columns 7 and 8 are the lower and upper bounds of the 95% confidence interval of coverage uncertainties around the ensemble median.  
Columns 9 and 10 are the lower and upper bounds of the 95% confidence interval of the combination of measurement and sampling and bias uncertainties.  
Columns 11 and 12 are the lower and upper bounds of the 95% confidence interval of the combined effects of all the uncertainties described in the HadCRUT4 error model (measurement and sampling, bias and coverage uncertainties).  


##Time series are presented as temperature anomalies (deg C) relative to 1961-1990.
```{r urls}
annualGlobalUrl="https://www.metoffice.gov.uk/hadobs/hadcrut4/data/current/time_series/HadCRUT.4.6.0.0.annual_ns_avg.txt" 
annGloCols=c("year",
                "anomaly",
                "l95ibias",
                "u95ibias",
                "l95unc",
                "u95unc",
                "l95med",
                "u95med",
                "l95cmb",
                "u95cmb",
                "l95all",
                "u95all")

annGloTypes=cols("year"=col_integer(),
                "anomaly"=col_number(),
                "l95ibias"=col_number(),
                "u95ibias"=col_number(),
                "l95unc"=col_number(),
                "u95unc"=col_number(),
                "l95med"=col_number(),
                "u95med"=col_number(),
                "l95cmb"=col_number(),
                "u95cmb"=col_number(),
                "l95all"=col_number(),
                "u95all"=col_number())

annualGlobal=read_delim(url(annualGlobalUrl),delim=" ",
                        col_names = annGloCols,
                        col_types =annGloTypes) %>%
  mutate(lerr=anomaly-l95all,
         uerr=u95all-anomaly,
         spread=(u95all-l95all)/2 )
saveRDS(annualGlobal,"ukglobal.rds")
seriesMin=(min(annualGlobal$anomaly))
seriesMax=(max(annualGlobal$anomaly))
seriesSpread=(max(annualGlobal$anomaly)-min(annualGlobal$anomaly))
```

```{r baseyears-fcn}
basestats<-function(syear=1960,intervalLength=30){
eyear=syear+intervalLength
baset=annualGlobal %>%
  filter(year>=syear) %>%
  filter(year<=eyear)
baseline=(sum(baset$anomaly))
basespread=(max(baset$anomaly)-min(baset$anomaly))

stats=glue("Function output: The total series spread id {seriesSpread} and the baseline anomaly for the years {syear} through {eyear} inclusive is {baseline} with a spread of {basespread}")
print(stats)
return(baset)
}
```

```{r calc-baseperiods}
basePeriod=basestats()
for (byear in seq(1930,1990,10)){
  bp=basestats(byear)
}

```


